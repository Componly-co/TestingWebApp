import { ParseError, ParseSourceSpan } from '../parse_util';
import { InterpolationConfig } from './interpolation_config';
import { TagDefinition } from './tags';
import { Token, TokenType } from './tokens';
export declare class TokenError extends ParseError {
    tokenType: TokenType | null;
    constructor(errorMsg: string, tokenType: TokenType | null, span: ParseSourceSpan);
}
export declare class TokenizeResult {
    tokens: Token[];
    errors: TokenError[];
    nonNormalizedIcuExpressions: Token[];
    constructor(tokens: Token[], errors: TokenError[], nonNormalizedIcuExpressions: Token[]);
}
export interface LexerRange {
    startPos: number;
    startLine: number;
    startCol: number;
    endPos: number;
}
export interface TokenizeOptions {
    tokenizeExpansionForms?: boolean;
    interpolationConfig?: InterpolationConfig;
    range?: LexerRange;
    escapedString?: boolean;
    i18nNormalizeLineEndingsInICUs?: boolean;
    leadingTriviaChars?: string[];
    preserveLineEndings?: boolean;
    tokenizeBlocks?: boolean;
}
export declare function tokenize(source: string, url: string, getTagDefinition: (tagName: string) => TagDefinition, options?: TokenizeOptions): TokenizeResult;
interface CharacterCursor {
    init(): void;
    peek(): number;
    advance(): void;
    getSpan(start?: this, leadingTriviaCodePoints?: number[]): ParseSourceSpan;
    getChars(start: this): string;
    charsLeft(): number;
    diff(other: this): number;
    clone(): CharacterCursor;
}
export declare class CursorError {
    msg: string;
    cursor: CharacterCursor;
    constructor(msg: string, cursor: CharacterCursor);
}
export {};
//# sourceMappingURL=lexer.d.ts.map